# version: "3.8"  # Obsolete in Docker Compose v2
services:
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 16G
        reservations:
          cpus: '1.0'
          memory: 4G
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - ollama
      - redis
    environment:
      APP_HOST: 0.0.0.0
      APP_PORT: 8000
      ALLOWED_ORIGINS: "*"
      WHISPER_MODEL: ${WHISPER_MODEL:-base}
      WHISPER_COMPUTE_TYPE: ${WHISPER_COMPUTE_TYPE:-int8}
      WHISPER_DOWNLOAD_ROOT: /models
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.1:8b}
      OLLAMA_TIMEOUT_SECONDS: ${OLLAMA_TIMEOUT_SECONDS:-60}
      BASIC_AUTH_USERNAME: ${BASIC_AUTH_USERNAME:-}
      BASIC_AUTH_PASSWORD: ${BASIC_AUTH_PASSWORD:-}
      REDIS_URL: redis://redis:6379
      QUEUE_MAX_WORKERS: ${QUEUE_MAX_WORKERS:-2}
      USE_QUEUE_SYSTEM: ${USE_QUEUE_SYSTEM:-true}
      MAX_CONCURRENCY: ${MAX_CONCURRENCY:-1}
      MAX_UPLOAD_MB: ${MAX_UPLOAD_MB:-100}
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - whisper_models:/models

  # Frontend will run on your local computer, not on VPS
  # frontend:
  #   build:
  #     context: ./frontend
  #     dockerfile: Dockerfile
  #   restart: unless-stopped
  #   depends_on:
  #     - backend
  #   ports:
  #     - "8080:80"
  #   healthcheck:
  #     test: ["CMD-SHELL", "wget -q --spider http://localhost/ || exit 1"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "6385:6379"
    volumes:
      - redis_data:/data
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  ollama_models:
  whisper_models:
  redis_data:

