# version: "3.8"  # Obsolete in Docker Compose v2
services:
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    deploy:
      resources:
        limits:
          cpus: '6.0'  # Use all 6 vCPU cores for better performance
          memory: 18G  # Increased from 12G to 18G for better model performance
        reservations:
          cpus: '3.0'
          memory: 12G
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
      - OLLAMA_NUM_PARALLEL=6  # Use all 6 vCPU cores
      - OLLAMA_CPU_THREADS=12  # Double the threads for better performance
      - OLLAMA_GPU_LAYERS=0    # CPU-only mode
      - OLLAMA_CPU_AVX=1       # Enable AVX instructions
      - OLLAMA_CPU_AVX2=1      # Enable AVX2 instructions
      - OLLAMA_CPU_F16=1       # Enable F16 precision
      - OLLAMA_CPU_MKL=1       # Enable Intel MKL optimization
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 5

  backend:
    build:
      context: .
      dockerfile: ./backend/Dockerfile
    restart: unless-stopped
    depends_on:
      - ollama
      - redis
    env_file:
      - .env  # Load all variables from centralized .env file
    environment:
      # Override specific Docker networking values
      OLLAMA_BASE_URL: http://ollama:11434  # Docker service name for internal communication
      REDIS_URL: redis://redis:6379  # Docker service name for internal communication
      WHISPER_DOWNLOAD_ROOT: ./models
    ports:
      - "8000:8000"
    deploy:
      resources:
        limits:
          cpus: '4.0'  # Backend processing
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - whisper_models:/models

  # Frontend will run on your local computer, not on VPS
  # frontend:
  #   build:
  #     context: ./frontend
  #     dockerfile: Dockerfile
  #   restart: unless-stopped
  #   depends_on:
  #     - backend
  #   ports:
  #     - "8080:80"
  #   healthcheck:
  #     test: ["CMD-SHELL", "wget -q --spider http://localhost/ || exit 1"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "6385:6379"
    volumes:
      - redis_data:/data
    deploy:
      resources:
        limits:
          cpus: '1.0'  # Minimal Redis resources
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  ollama_models:
  whisper_models:
  redis_data:

