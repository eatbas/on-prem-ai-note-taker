# Backend Environment Configuration - VPS SIDE
# Copy this file to .env and fill in your values

# =============================================================================
# APP CONFIGURATION
# =============================================================================

APP_HOST=0.0.0.0                      # Bind address (required for external access)
APP_PORT=8000                          # Port number
LOG_LEVEL=INFO                         # Log level: DEBUG, INFO, WARNING, ERROR

# =============================================================================
# VPS OPTIMIZATIONS (OPTIMIZED for 6-core VPS)
# =============================================================================

# Whisper Settings (OPTIMIZED for 3x speed)
WHISPER_MODEL=tiny                    # Model size: tiny=3x faster, base=balanced, small/medium/large=slower
WHISPER_COMPUTE_TYPE=int8             # Compute type: int8=fastest, int16=slower, float16/float32=slowest
WHISPER_DEVICE=cpu                    # Force CPU usage for VPS
WHISPER_CPU_THREADS=6                 # Optimize for 6 vCPU VPS (use 6 out of 8 cores)
WHISPER_MEMORY_LIMIT_GB=16           # Memory limit for Whisper (leaves 8GB for system)
WHISPER_BEAM_SIZE=1                   # Beam size for CPU optimization (1=fastest, 5=better quality)
WHISPER_DOWNLOAD_ROOT=./models        # Local model storage (VPS path)

# Ollama Settings (OPTIMIZED for 3x speed)
OLLAMA_BASE_URL=http://ollama:11434  # Ollama service URL (Docker service name for internal communication)
OLLAMA_MODEL=qwen2.5:3b-instruct      # OPTIMIZED: Fast 3B model perfect for meeting notes (1.9GB, 6-7s response)
OLLAMA_TIMEOUT_SECONDS=180            # Request timeout (increased for complex Turkish/English summaries)
OLLAMA_CPU_THREADS=12                 # OPTIMIZED: Double CPU threads for better performance
OLLAMA_MEMORY_LIMIT_GB=18             # OPTIMIZED: Increased memory for better model performance

# =============================================================================
# OLLAMA PERFORMANCE OPTIMIZATIONS (NEW)
# =============================================================================

OLLAMA_NUM_PARALLEL=6                 # OPTIMIZED: Use all 6 vCPU cores for parallel processing
OLLAMA_CPU_AVX=1                      # Enable AVX instructions for better CPU performance
OLLAMA_CPU_AVX2=1                     # Enable AVX2 instructions for better CPU performance
OLLAMA_CPU_F16=1                      # Enable F16 precision for better performance
OLLAMA_CPU_MKL=1                      # Enable Intel MKL optimization

# =============================================================================
# LANGUAGE RESTRICTIONS (OPTIMIZED for speed)
# =============================================================================

ALLOWED_LANGUAGES=tr,en               # OPTIMIZED: EN+TR only (20-25% speed boost vs auto-detect)
FORCE_LANGUAGE_VALIDATION=true        # Strict language validation (prevents errors)

# =============================================================================
# SPEAKER IDENTIFICATION (NEW FEATURE)
# =============================================================================

ENABLE_SPEAKER_IDENTIFICATION=true    # Enable speaker differentiation in transcripts
SPEAKER_CHANGE_THRESHOLD_MS=1000     # Speaker change detection threshold (1 second silence)
MAX_SPEAKERS=5                        # Maximum number of speakers to identify

# =============================================================================
# PROGRESS TRACKING
# =============================================================================

ENABLE_PROGRESS_TRACKING=true         # Enable progress tracking
PROGRESS_UPDATE_INTERVAL_MS=500       # Progress update frequency
ENABLE_SSE=true                       # Enable Server-Sent Events

# =============================================================================
# QUEUE SYSTEM
# =============================================================================

USE_QUEUE_SYSTEM=true                 # Enable Redis-based job queuing
REDIS_URL=redis://redis:6385          # Redis connection URL (Docker service name for internal communication)
QUEUE_MAX_WORKERS=2                   # Maximum concurrent workers

# =============================================================================
# PERFORMANCE & RESOURCES (OPTIMIZED for VPS)
# =============================================================================

MAX_CONCURRENCY=3                     # OPTIMIZED: Increased to 3 concurrent transcriptions (using all 6 vCPU cores)
MAX_UPLOAD_MB=200                     # OPTIMIZED: Increased to 200MB for longer meetings (supports 2+ hour meetings)

# =============================================================================
# AUTHENTICATION (REQUIRED for Security)
# =============================================================================

BASIC_AUTH_USERNAME=myca              # HTTP Basic Auth username (REQUIRED - change this!)
BASIC_AUTH_PASSWORD=wj2YyxrJ4cqcXgCA # HTTP Basic Auth password (REQUIRED - change this!)

# =============================================================================
# CORS & SECURITY
# =============================================================================

ALLOWED_ORIGINS=http://localhost:5173,http://95.111.244.159,null

# =============================================================================
# DATABASE
# =============================================================================

DATABASE_URL=sqlite:///./app.db        # SQLite database path
DATABASE_ECHO=false                    # SQL query logging

# =============================================================================
# DEVELOPMENT
# =============================================================================

DEBUG=false                            # Debug mode
RELOAD=false                           # Auto-reload on code changes

# =============================================================================
# IMPORTANT NOTES
# =============================================================================
# 1. This file goes on your VPS at /myca/on-prem-ai-note-taker/backend/.env
# 2. Ollama runs on same VPS at http://localhost:11434
# 3. Redis runs on same VPS at redis://localhost:6385
# 4. Backend API accessible at http://95.111.244.159:8000
# 5. Frontend connects from your laptop to this VPS
# 6. CHANGE THE DEFAULT PASSWORDS for security!
# 7. NEW: Using qwen2.5:3b-instruct model for optimal performance (6-7s response time)
# 8. NEW: Speaker identification enabled for better meeting transcripts
# 9. NEW: Optimized for 6 vCPU VPS with 18GB memory allocation
