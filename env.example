# ===== On-Prem AI Note Taker - CENTRALIZED Environment Configuration =====
# üéØ SINGLE SOURCE OF TRUTH: Copy this to .env and use everywhere!
# 
# ‚úÖ This file now powers:
#    - Backend (via env_loader.py)
#    - Frontend (via envLoader.ts) 
#    - Docker (via env_file: .env)
#    - Electron (reads from root .env)
#
# üîí SECURITY: All hardcoded credentials removed - everything loads from here!
#
# üê≥ DEPLOYMENT MODES:
# 1. Full Docker: All services (backend, Redis, Ollama) in Docker containers
#    - Use: redis://redis:6379, http://ollama:11434 (Docker service names)
# 2. Hybrid: Backend with venv, Redis & Ollama in Docker containers  
#    - Use: redis://localhost:6385, http://localhost:11434 (localhost ports)
#
# üéØ CURRENT CONFIG: Full Docker mode (production ready)

# =============================================================================
# VPS SERVER CONFIGURATION 
# =============================================================================

# ===== Application Server =====
APP_HOST=0.0.0.0                    # Bind to all interfaces (required for external access)
APP_PORT=8000                       # Backend API port

# ===== MAXIMUM ACCURACY WHISPER.CPP CONFIGURATION =====
# whisper.cpp service provides better CPU performance and lower memory usage
WHISPER_CPP_URL=http://whisper-cpp:8001  # whisper.cpp service URL (Docker)
WHISPER_MODEL=large-v2               # Model served by whisper.cpp service
WHISPER_COMPUTE_TYPE=int8           # Handled by whisper.cpp service internally  
WHISPER_DEVICE=cpu                  # Force CPU usage for VPS
WHISPER_CPU_THREADS=6
WHISPER_MEMORY_LIMIT_GB=6           # Reduced - whisper.cpp is more memory efficient

# ===== MAXIMUM QUALITY SETTINGS =====
WHISPER_BEAM_SIZE=5
WHISPER_BEST_OF=5
WHISPER_TEMPERATURE=0.0             # Deterministic output
WHISPER_CONDITION_ON_PREVIOUS_TEXT=true # CRITICAL: Improve continuity across segments
WHISPER_WORD_TIMESTAMPS=true
WHISPER_LOG_PROB_THRESHOLD=-1.0     # Log probability threshold
WHISPER_COMPRESSION_RATIO_THRESHOLD=2.4 # Compression ratio threshold
WHISPER_DOWNLOAD_ROOT=./models      # Local model storage (VPS path)

# ===== ENHANCED CONTEXT FOR MAXIMUM QUALITY =====
WHISPER_INITIAL_PROMPT="This is a professional meeting or conversation with multiple speakers. Please transcribe accurately with proper punctuation and speaker identification. Focus on clarity, speaker transitions, and technical terminology."

# ===== STAGE 1: Enhanced VAD Settings =====
WHISPER_NO_SPEECH_THRESHOLD=0.3     # OPTIMIZED: More sensitive detection (was 0.4)
WHISPER_HALLUCINATION_SILENCE_THRESHOLD=1.5  # OPTIMIZED: Faster response (was 2.0)
WHISPER_VAD_MIN_SILENCE_MS=200       # OPTIMIZED: Shorter silence detection (was 300)
WHISPER_VAD_SPEECH_PAD_MS=100        # OPTIMIZED: Less padding for responsiveness (was 150)

# ===== Ollama Configuration (OPTIMIZED for VPS) =====
# For Docker setup: use http://ollama:11434 (Docker service name)
# For hybrid setup (venv backend + Docker Ollama): use http://localhost:11434
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=qwen2.5:3b-instruct
OLLAMA_TIMEOUT_SECONDS=180
OLLAMA_MEMORY_LIMIT_GB=18

# ===== STAGE 1: CPU Thread Optimization =====
# Optimized thread allocation for 6-core VPS (10-20% speed improvement)
ASR_THREADS=4                           # Dedicate 4 cores to Whisper ASR
OMP_NUM_THREADS=4                       # OpenMP consistency for ASR
WHISPER_CPU_THREADS=4                   # Match ASR threads

# ===== Ollama Performance Optimizations =====
OLLAMA_CPU_THREADS=6                    # Use remaining + hyper-threading for LLM
OLLAMA_NUM_PARALLEL=1                   # Prevent thrashing on CPU-only (OPTIMIZED)
OLLAMA_CPU_AVX=1
OLLAMA_CPU_AVX2=1
OLLAMA_CPU_F16=1
OLLAMA_CPU_MKL=1

# ===== Performance & Resources =====
MAX_CONCURRENCY=2                       # OPTIMIZED: Reduced from 3 to prevent CPU overload
QUEUE_MAX_WORKERS=2                     # Match concurrency limit
MAX_UPLOAD_MB=200

# ===== STAGE 1: Audio Preprocessing Optimizations =====
# Audio normalization provides 15-25% improvement in transcription accuracy
ENABLE_AUDIO_NORMALIZATION=true
AUDIO_NORMALIZATION_TIMEOUT=120

# Enhanced VAD (Voice Activity Detection) - 5-10% accuracy improvement
ENHANCED_VAD_ENABLED=true
VAD_AGGRESSIVENESS=2                    # 0-3, 2 = balanced sensitivity
VAD_FRAME_DURATION=30                   # 30ms frames for better detection

# ===== STAGE 2: Hierarchical Summarization Revolution =====
# Map-Reduce hierarchical summarization - 40-60% quality improvement
ENABLE_HIERARCHICAL_SUMMARIZATION=true
HIERARCHICAL_CHUNK_SIZE=4000            # Character count per intelligent chunk
HIERARCHICAL_MAX_CHUNKS=20              # Maximum chunks to process

# ===== STAGE 3: Schema-first JSON Output =====
# Forces LLM to output structured JSON - 25-40% actionable content improvement
ENABLE_SCHEMA_FIRST_JSON=true
JSON_VALIDATION_STRICT=false           # Whether to fail on JSON validation errors
JSON_RETRY_ATTEMPTS=2                  # Number of retries for invalid JSON

# ===== Language Restrictions (OPTIMIZED for speed) =====
ALLOWED_LANGUAGES=tr,en
FORCE_LANGUAGE_VALIDATION=true

# ===== ENHANCED SPEAKER IDENTIFICATION =====
ENABLE_SPEAKER_IDENTIFICATION=true
SPEAKER_CHANGE_THRESHOLD_MS=800
MAX_SPEAKERS=6
SPEAKER_SIMILARITY_THRESHOLD=0.7

# ===== OPTIMIZED CHUNKING FOR SPEAKER PERSISTENCE =====
CHUNK_DURATION_SECONDS=45
CHUNK_OVERLAP_SECONDS=8

# ===== Progress Tracking =====
ENABLE_PROGRESS_TRACKING=true        # Enable progress tracking
PROGRESS_UPDATE_INTERVAL_MS=500      # Progress update frequency
ENABLE_SSE=true                      # Enable Server-Sent Events

# ===== Queue System =====
USE_QUEUE_SYSTEM=true                # Enable Redis-based job queuing
# For Docker setup: use redis://redis:6379 (Docker service name)
# For hybrid setup (venv backend + Docker Redis): use redis://localhost:6385
REDIS_URL=redis://redis:6379
QUEUE_MAX_WORKERS=3

# ===== Celery Configuration =====
# For Docker setup: use redis://redis:6379/0
# For hybrid setup (venv backend + Docker Redis): use redis://localhost:6385/0
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0
CELERY_TASK_TRACK_STARTED=true
CELERY_TASK_SERIALIZER=json
CELERY_ACCEPT_CONTENT=json
CELERY_RESULT_SERIALIZER=json
CELERY_TIMEZONE=UTC
CELERY_ENABLE_UTC=true
CELERY_WORKER_CONCURRENCY=3
CELERY_WORKER_PREFETCH_MULTIPLIER=1
CELERY_TASK_ACKS_LATE=true
CELERY_WORKER_DISABLE_RATE_LIMITS=true

# ===== AUTHENTICATION (REQUIRED for Security) =====
# üîí SECURE: Set these to protect your API - CHANGE THESE PASSWORDS!
# üéØ CENTRALIZED: These credentials work for ALL components (frontend, backend, electron)
BASIC_AUTH_USERNAME=myca
BASIC_AUTH_PASSWORD=wj2YyxrJ4cqcXgCA
# These VITE_ variables are automatically available to frontend
VITE_API_BASE_URL=http://95.111.244.159:8000/api
VITE_AUDIO_CHUNK_MS=45000           # 45-second chunks for optimal speaker tracking  
VITE_MAX_FILE_SIZE_MB=200           # Support for 2+ hour meetings
VITE_WHISPER_MODEL=large-v3
VITE_ENABLE_SPEAKER_TRACKING=true   # Enable speaker features in UI
VITE_ENABLE_PROGRESS_TRACKING=true  # Show detailed progress
VITE_ENABLE_SSE=true               # Real-time updates
VITE_DEFAULT_LANGUAGE=auto         # Smart language detection

# ===== Logging =====
LOG_LEVEL=INFO                       # Log level: DEBUG, INFO, WARNING, ERROR

# ===== CORS & Security =====
# CORS origins
# - To allow everything (useful for Electron app and mixed local/VPS access), keep "*"
# - To restrict, use a comma-separated list (e.g. "http://localhost:5173,http://95.111.244.159,null")
#   Note: Backend is configured to support wildcard using allow_origin_regex, even with credentials.
ALLOWED_ORIGINS=electron://app,http://localhost:5173,http://95.111.244.159:5173,https://localhost:5173

# =============================================================================
# üéØ CENTRALIZED SYSTEM - NO MORE MULTIPLE ENV FILES! 
# =============================================================================
# 
# ‚úÖ OLD WAY (3 separate files):        ‚ùå NEW WAY (1 centralized file):
#    - backend/.env                     - Copy this to .env  
#    - frontend/.env.local              - Everything loads from there!
#    - main/.env                        - No more copy-pasting!
#
# üöÄ ELECTRON CONFIGURATION (Auto-loaded from root .env)
# -------------------------------------------------------
ELECTRON_BACKEND_PORT=8002           # Local backend port for Electron app
ELECTRON_API_BASE_URL=http://localhost:8002/api  # Electron backend URL

# üîß DEVELOPMENT OVERRIDES (Uncomment for local development)
# -------------------------------------------------------
# Uncomment these lines if you want to override settings for local development:
#
# For local backend development:
# APP_PORT=8001
# OLLAMA_BASE_URL=http://95.111.244.159:11434  # Point to VPS Ollama
# REDIS_URL=redis://95.111.244.159:6385        # Point to VPS Redis
# WHISPER_CPP_URL=http://95.111.244.159:8001   # Point to VPS whisper.cpp service
#
# For local frontend development: 
# VITE_API_BASE_URL=http://localhost:8001/api   # Point to local backend
#
# For maximum local performance (smaller model):
# WHISPER_MODEL=large-v3
# WHISPER_BEAM_SIZE=5
# WHISPER_BEST_OF=5

# =============================================================================
# VPS INFORMATION (for reference) =====
VPS_HOST=95.111.244.159
VPS_USER=$USER
VPS_PORT=22

# =============================================================================
# üéØ CENTRALIZED CONFIGURATION SYSTEM - QUICK START GUIDE
# =============================================================================

# üöÄ SETUP INSTRUCTIONS:
# 1. Copy this file to .env: cp env.example .env
# 2. Edit your credentials in .env (change username/password above)
# 3. Start services: docker-compose up -d
# 4. Access UI at: http://95.111.244.159:5173

# üèóÔ∏è ARCHITECTURE:
# - Backend: http://95.111.244.159:8000 (loads from root .env)
# - Frontend: http://95.111.244.159:5173 (loads from root .env) 
# - Ollama: http://ollama:11434 (internal) / http://95.111.244.159:11434 (external)
# - Redis: redis://redis:6379 (internal) / 95.111.244.159:6385 (external)

# üîí SECURITY FEATURES:
# - ‚úÖ No hardcoded credentials anywhere in code
# - ‚úÖ Centralized authentication (one place to update)
# - ‚úÖ Environment validation (fails safely if misconfigured)
# - ‚úÖ Git security (.env ignored, only templates committed)

# üéØ PERFORMANCE OPTIMIZATIONS:
# - ‚úÖ Whisper large-v3 model (70-80% better accuracy than base)
# - ‚úÖ 45-second chunks with 8-second overlap (optimal speaker tracking)
# - ‚úÖ Enhanced speaker persistence across entire meetings  
# - ‚úÖ Word timestamps enabled for better segmentation
# - ‚úÖ Optimized for 16GB RAM and 6 vCPU VPS

# üõ†Ô∏è USAGE:
# - Recording: 45-second chunks with enhanced speaker tracking
# - Processing: Large-v3 Whisper model with maximum quality settings
# - Summarization: qwen2.5:3b-instruct (6-7s response time)
# - Languages: Turkish and English optimized (20-25% speed boost)

# üì± ELECTRON SUPPORT:
# - Desktop app automatically loads from this .env file
# - Mini recorder with floating window controls
# - System audio + microphone recording
# - Offline capable with VPS sync

# üîß TROUBLESHOOTING:
# - Run security audit: ./scripts/remove-hardcoded-creds.sh audit  
# - Validate config: ./scripts/validate-env-security.sh validate
# - View logs: docker-compose logs -f backend
VITE_DEV_MODE=true
